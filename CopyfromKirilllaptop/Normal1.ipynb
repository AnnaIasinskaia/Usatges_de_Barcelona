{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import AnnDiplomMatrix\n",
    "import numpy as np\n",
    "from scipy.spatial import distance\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ContextAnalyse(path1, path2, lemma = False):\n",
    "    #print(\"Load matrix 1 from file:\", path1)\n",
    "    x = AnnDiplomMatrix.text2matrixNdict(path1, lemma)\n",
    "    #print(\"Load matrix 2 from file:\", path2)\n",
    "    y = AnnDiplomMatrix.text2matrixNdict(path2, lemma)\n",
    "    \n",
    "    g = list(x.numeratedDict.keys())+list(y.numeratedDict.keys())\n",
    "    g = list(set(g))\n",
    "    g.sort()\n",
    "    max_size = len(g)\n",
    "    numeratedDict_g = dict(zip(g, range(max_size)))\n",
    "    new_matrix_x = np.zeros((max_size, max_size))\n",
    "    new_matrix_y = np.zeros((max_size, max_size))\n",
    "    start_t = time.clock()\n",
    "    for i in g:\n",
    "        \n",
    "        for j in g:\n",
    "            #print(i, j)\n",
    "            if i in x.numeratedDict.keys() and j in x.numeratedDict.keys():\n",
    "                i_i = x.numeratedDict[i]\n",
    "                j_j = x.numeratedDict[j]\n",
    "\n",
    "                new_matrix_x[numeratedDict_g[i], numeratedDict_g[j]] = x.matrix[i_i, j_j]      \n",
    "    for i in g:\n",
    "\n",
    "        for j in g:\n",
    "            #print(i, j)\n",
    "            if i in y.numeratedDict.keys() and j in y.numeratedDict.keys():\n",
    "                i_i = y.numeratedDict[i]\n",
    "                j_j = y.numeratedDict[j]\n",
    "\n",
    "                new_matrix_y[numeratedDict_g[i], numeratedDict_g[j]] = y.matrix[i_i, j_j]    \n",
    "    a = new_matrix_x.flatten()\n",
    "    b = new_matrix_y.flatten()\n",
    "    return distance.cosine(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def FrequencyAnalyse(path1, path2, lemma = False):\n",
    "    x = AnnDiplomMatrix.text2matrixNdictFreq(path1, lemma)\n",
    "    y = AnnDiplomMatrix.text2matrixNdictFreq(path2, lemma)\n",
    "    g = list(x.numeratedDict.keys())+list(y.numeratedDict.keys())\n",
    "    g = list(set(g))\n",
    "    g.sort()\n",
    "    max_size = len(g)\n",
    "    numeratedDict_g = dict(zip(g, range(max_size)))\n",
    "\n",
    "    new_matrix_x = np.zeros((max_size))\n",
    "    new_matrix_y = np.zeros((max_size))\n",
    "\n",
    "    for i in g:\n",
    "        #print(i, j)\n",
    "        if i in x.numeratedDict.keys() and i in x.numeratedDict.keys():\n",
    "            i_i = x.numeratedDict[i]\n",
    "            new_matrix_x[numeratedDict_g[i]] = x.matrix[i_i]   \n",
    "    for i in g:\n",
    "        #print(i, j)\n",
    "        if i in y.numeratedDict.keys() and i in y.numeratedDict.keys():\n",
    "            i_i = y.numeratedDict[i]\n",
    "            new_matrix_y[numeratedDict_g[i]] = y.matrix[i_i] \n",
    "\n",
    "    a = new_matrix_x.flatten()\n",
    "    b = new_matrix_y.flatten()\n",
    "    return distance.cosine(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#path1 = \"Latin.docx\"\n",
    "#path2 = \"Этимологии.docx\"\n",
    "\n",
    "#print(\"Context cosine:\", round(ContextAnalyse(path1, path2),4))\n",
    "#print(\"Frequency cosine:\", round(FrequencyAnalyse(path1, path2),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exeptionis Legum Romanorum Petri.docx\n",
      "Context cosine: 0.7002\n",
      "Frequency cosine: 0.8821\n"
     ]
    }
   ],
   "source": [
    "path = \"Latin.docx\"\n",
    "files2an = [\n",
    "    \"Exeptionis Legum Romanorum Petri.docx\"\n",
    "]\n",
    "for x in files2an:\n",
    "    print(x)\n",
    "    #print(\"Context cosine calculating\")\n",
    "    print(\"Context cosine:\", round(ContextAnalyse(path, x, True),4))\n",
    "    \n",
    "    #print(\"Frequency cosine calculating\")\n",
    "    print(\"Frequency cosine:\", round(FrequencyAnalyse(path, x, True),4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"Latin.docx\"\n",
    "y = AnnDiplomMatrix.text2matrixNdictFreq(path, True)\n",
    "L=list(y.numeratedDict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AnnDiplomMatrix.DictLatCrossFreq at 0x7fb0272f2c50>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "files2an = [\n",
    "    \"Exeptionis Legum Romanorum Petri.docx\",\n",
    "    \"Latin.docx\",\n",
    "    \"EVANGELIUM.docx\",\n",
    "    \"Isidori Hispalensis Episcopi Etymologiarum.docx\",\n",
    "    \"Corpus Juris Civilis.docx\",\n",
    "    \"Lex Visigothorum.docx\"\n",
    "]\n",
    "frames = []\n",
    "for path in files2an:\n",
    "    y = AnnDiplomMatrix.text2matrixNdictFreq(path, True)\n",
    "    L=list(y.numeratedDict.keys())\n",
    "    df = pd.DataFrame()\n",
    "    df['word']= L\n",
    "    df['doc']=[path]*len(L)\n",
    "    frames.append(df)\n",
    "df_full=pd.concat(frames)\n",
    "df_full.to_csv('unified_texts.csv', index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
